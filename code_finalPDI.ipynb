{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de Código de Barras em Produtos\n",
    "\n",
    "**Grupo 8**\n",
    "Processamento Digital de Imagens\n",
    "Departamento de Computação - São Carlos, SP - Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image as IPyImage\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Função Principal de Processamento\n",
    "A função `detectar_codigo_barras` é o coração do nosso sistema. Ela recebe o caminho de uma imagem e uma série de parâmetros ajustáveis para realizar a detecção de códigos de barras. O processo envolve as seguintes etapas, detalhadas nos comentários do código a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_codigo_barras(image_path, kernel_size=(25, 3), sobel_threshold=0, min_line_length=50):\n",
    "    \"\"\"\n",
    "    Processa uma imagem para detectar a região de um código de barras.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Caminho para o arquivo de imagem.\n",
    "        kernel_size (tuple): Tamanho do kernel para a operação de fechamento morfológico.\n",
    "        sobel_threshold (int): Limiar para a binarização do gradiente Sobel. Se 0, usa THRESH_OTSU.\n",
    "        min_line_length (int): Comprimento mínimo da linha para a detecção de Hough.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Um dicionário com as imagens de cada etapa do processo e os pontos do retângulo (bbox) que envolve o código de barras detectado.\n",
    "    \"\"\"\n",
    "    resultados = {}\n",
    "    \n",
    "    # --- 1. Leitura da Imagem ---\n",
    "    # O que faz: Carrega a imagem do caminho especificado.\n",
    "    # Por que: É o ponto de partida do processo. Inclui uma verificação para garantir que o arquivo existe.\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"[ERRO] Imagem {image_path} não encontrada.\")\n",
    "        return None, None\n",
    "    \n",
    "    # --- 2. Redimensionamento ---\n",
    "    # O que faz: Altera as dimensões da imagem para um tamanho padrão (600x400 pixels).\n",
    "    # Por que: Garante que os parâmetros (como tamanho de kernel e de linha) funcionem de forma consistente \n",
    "    # em imagens de diferentes resoluções originais.\n",
    "    image_resized = cv2.resize(image.copy(), (600, 400))\n",
    "    resultados['original'] = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # --- 3. Conversão para Escala de Cinza ---\n",
    "    # O que faz: Converte a imagem colorida (BGR) para escala de cinza.\n",
    "    # Por que: A cor não é necessária para detectar a estrutura de um código de barras. A conversão \n",
    "    # simplifica a imagem para informações de luminância, reduzindo a complexidade computacional.\n",
    "    gray = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "    resultados['escala_cinza'] = gray\n",
    "    \n",
    "    # --- 4. Desfoque Gaussiano ---\n",
    "    # O que faz: Aplica um filtro de desfoque (blur) para suavizar a imagem.\n",
    "    # Por que: Reduz ruídos de alta frequência (como texturas finas ou imperfeições da imagem), \n",
    "    # o que ajuda a prevenir a detecção de falsas bordas na etapa seguinte.\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    resultados['desfoque_gaussiano'] = blurred\n",
    "    \n",
    "    # --- 5. Gradiente Sobel ---\n",
    "    # O que faz: Calcula a derivada (gradiente) da imagem na direção X.\n",
    "    # Por que: Códigos de barras são compostos por barras verticais. O operador Sobel no eixo X realça \n",
    "    # intensamente essas bordas verticais, fazendo com que a região do código de barras se destaque.\n",
    "    gradX = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=3)\n",
    "    gradX = cv2.convertScaleAbs(gradX)\n",
    "    resultados['gradiente_sobel'] = gradX\n",
    "    \n",
    "    # --- 6. Binarização (Limiarização) ---\n",
    "    # O que faz: Converte a imagem de gradiente em uma imagem binária (preto e branco).\n",
    "    # Por que: Separa as regiões de interesse (bordas fortes) do fundo. Usamos o método de Otsu \n",
    "    # (THRESH_OTSU) para encontrar um limiar ótimo automaticamente, tornando o método mais adaptável.\n",
    "    if sobel_threshold == 0:\n",
    "        _, thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    else:\n",
    "        _, thresh = cv2.threshold(gradX, sobel_threshold, 255, cv2.THRESH_BINARY)\n",
    "    resultados['binarizacao'] = thresh\n",
    "    \n",
    "    # --- 7. Fechamento Morfológico ---\n",
    "    # O que faz: Aplica uma operação de fechamento (dilatação seguida de erosão) com um kernel retangular.\n",
    "    # Por que: O kernel retangular e alongado (kernel_size) ajuda a fechar os espaços entre as barras \n",
    "    # verticais do código, unindo a região fragmentada em um bloco sólido.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, kernel_size)\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    resultados['fechamento_morfologico'] = closed\n",
    "    \n",
    "    # --- 8. Refinamento Morfológico ---\n",
    "    # O que faz: Aplica erosão e dilatação sequencialmente.\n",
    "    # Por que: Remove pequenos ruídos brancos (pontos isolados) que possam ter sobrado após o fechamento, \n",
    "    # refinando a máscara da região candidata a ser um código de barras.\n",
    "    closed = cv2.erode(closed, None, iterations=2)\n",
    "    closed = cv2.dilate(closed, None, iterations=2)\n",
    "    resultados['refinamento_morfologico'] = closed\n",
    "        \n",
    "    # --- 9. Unificação das Regiões ---\n",
    "    # O que faz: Aplica mais operações morfológicas na máscara criada a partir das linhas de Hough.\n",
    "    # Por que: As linhas detectadas podem estar separadas. Erosão e dilatação com um kernel grande unificam \n",
    "    # essas linhas em uma única região coesa que representa o código de barras completo.\n",
    "    kernel_erode_dilate = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\n",
    "    mask_eroded = cv2.erode(closed, kernel_erode_dilate, iterations=1)\n",
    "    mask_dilated = cv2.dilate(mask_eroded, kernel_erode_dilate, iterations=1)\n",
    "    resultados['unificacao_regioes'] = mask_dilated\n",
    "    \n",
    "    # --- 10. Identificação e Contorno ---\n",
    "    # O que faz: Encontra todos os contornos na máscara final e seleciona o de maior área.\n",
    "    # Por que: Assumimos que o maior objeto coeso na imagem é o código de barras de interesse. \n",
    "    # Um retângulo de área mínima é então ajustado a este contorno para obter a localização precisa.\n",
    "    contours, _ = cv2.findContours(mask_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    image_with_detection = image_resized.copy()\n",
    "    bbox = None\n",
    "    \n",
    "    if contours:\n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        bbox = cv2.boxPoints(rect)\n",
    "        bbox = np.intp(bbox)\n",
    "        cv2.drawContours(image_with_detection, [bbox], -1, (0, 255, 0), 3)\n",
    "    \n",
    "    resultados['deteccao_final'] = cv2.cvtColor(image_with_detection, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return resultados, bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exemplos de Processamento por Etapas\n",
    "Esta seção demonstra o fluxo de processamento da detecção de código de barras, mostrando o resultado de cada etapa. Você pode selecionar diferentes imagens e ajustar os parâmetros para observar o impacto nas transformações visuais. **Pelo menos três imagens de exemplo devem ser visualizadas aqui.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = sorted(glob.glob('imagens/*.jpg'))\n",
    "\n",
    "# Limitar a seleção a pelo menos 3 imagens para demonstração, se houver mais\n",
    "display_image_files = image_files[:53] if len(image_files) >= 3 else image_files\n",
    "\n",
    "param_kernel_width = widgets.IntSlider(value=25, min=5, max=50, description='Largura Kernel:')\n",
    "param_kernel_height = widgets.IntSlider(value=3, min=1, max=10, description='Altura Kernel:')\n",
    "param_threshold = widgets.IntSlider(value=0, min=0, max=255, description='Limiar Sobel:')\n",
    "param_min_line = widgets.IntSlider(value=50, min=10, max=200, description='Min Linha:')\n",
    "image_selector = widgets.Dropdown(options=display_image_files, description='Imagem:')\n",
    "\n",
    "def update_processing(image_path, kernel_w, kernel_h, threshold, min_line):\n",
    "    resultados, _ = detectar_codigo_barras(\n",
    "        image_path, \n",
    "        kernel_size=(kernel_w, kernel_h),\n",
    "        sobel_threshold=threshold,\n",
    "        min_line_length=min_line\n",
    "    )\n",
    "    \n",
    "    if resultados is None:\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    etapas = [\n",
    "        ('original', 'Imagem Original'),\n",
    "        ('escala_cinza', 'Escala de Cinza'),\n",
    "        ('desfoque_gaussiano', 'Desfoque Gaussiano'),\n",
    "        ('gradiente_sobel', 'Gradiente Sobel (X)'),\n",
    "        ('binarizacao', 'Binarização'),\n",
    "        ('fechamento_morfologico', 'Fechamento Morfológico'),\n",
    "        ('refinamento_morfologico', 'Refinamento Morfológico'),\n",
    "        ('unificacao_regioes', 'Regiões Unificadas'),\n",
    "        ('deteccao_final', 'Detecção Final')\n",
    "    ]\n",
    "    \n",
    "    for i, (key, title) in enumerate(etapas, 1):\n",
    "        plt.subplot(4, 3, i)\n",
    "        if key in ['original', 'deteccao_final']:\n",
    "            plt.imshow(resultados[key])\n",
    "        else:\n",
    "            plt.imshow(resultados[key], cmap='gray')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "widgets.interactive(\n",
    "    update_processing,\n",
    "    image_path=image_selector,\n",
    "    kernel_w=param_kernel_width,\n",
    "    kernel_h=param_kernel_height,\n",
    "    threshold=param_threshold,\n",
    "    min_line=param_min_line\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Validação Humana das Detecções\n",
    "Nesta seção, você validará manualmente as detecções de código de barras para cada imagem. Para cada imagem, o sistema exibirá a detecção final e você deverá indicar se a detecção foi **bem-sucedida** ou **mal-sucedida**. Esta avaliação subjetiva é fundamental para entendermos a eficácia do algoritmo em cenários reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_validation_results = {\n",
    "    'total_images': 0,\n",
    "    'successful_detections': 0,\n",
    "    'failed_detections': 0\n",
    "}\n",
    "\n",
    "output_area = widgets.Output()\n",
    "success_button = widgets.Button(description=\"Sucesso\", button_style='success', icon='check')\n",
    "fail_button = widgets.Button(description=\"Falha\", button_style='danger', icon='times')\n",
    "start_validation_button = widgets.Button(description=\"Iniciar Validação\", button_style='info')\n",
    "\n",
    "# Esconde os botões de sucesso/falha inicialmente\n",
    "buttons_box = widgets.HBox([success_button, fail_button])\n",
    "buttons_box.layout.visibility = 'hidden'\n",
    "\n",
    "# Preparar o iterador de imagens\n",
    "all_image_files_for_validation = sorted(glob.glob('imagens/*.jpg'))\n",
    "image_iterator = iter(all_image_files_for_validation)\n",
    "\n",
    "def display_final_human_validation_stats():\n",
    "    # Limpa a área para mostrar apenas os resultados finais\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(\"Validação Humana Concluída!\")\n",
    "\n",
    "        # Verifica se alguma imagem foi validada para evitar divisão por zero\n",
    "        if human_validation_results['total_images'] > 0:\n",
    "            detection_rate = (human_validation_results['successful_detections'] / human_validation_results['total_images'] * 100)\n",
    "            print(\"\\n--- Resultados da Validação Humana ---\")\n",
    "            print(f\"Total de imagens validadas: {human_validation_results['total_images']}\")\n",
    "            print(f\"Detecções bem-sucedidas: {human_validation_results['successful_detections']}\")\n",
    "            print(f\"Detecções mal-sucedidas: {human_validation_results['failed_detections']}\")\n",
    "            print(f\"Taxa de Sucesso na Detecção: {detection_rate:.2f}%\")\n",
    "            \n",
    "            # Gráfico de resultados\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            validation_metrics = ['Bem-sucedidas', 'Mal-sucedidas']\n",
    "            validation_values = [human_validation_results['successful_detections'], human_validation_results['failed_detections']]\n",
    "            plt.bar(validation_metrics, validation_values, color=['lightgreen', 'salmon'])\n",
    "            plt.title('Resultados da Validação Humana')\n",
    "            plt.ylabel('Número de Imagens')\n",
    "            for i, v in enumerate(validation_values):\n",
    "                plt.text(i, v + 0.1, str(v), ha='center')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Nenhuma imagem foi validada.\")\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Bloco try...except para capturar o fim do iterador de forma segura\n",
    "        try:\n",
    "            # Tenta obter a próxima imagem\n",
    "            img_path = next(image_iterator)\n",
    "            \n",
    "            resultados, _ = detectar_codigo_barras(img_path)\n",
    "            if resultados is None:\n",
    "                print(f\"Não foi possível processar a imagem: {img_path}\")\n",
    "                on_button_clicked(None) # Pula para a próxima imagem automaticamente\n",
    "                return\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(resultados['deteccao_final'])\n",
    "            plt.title(f\"Detecção para: {os.path.basename(img_path)}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            # Se for o primeiro clique, exibe os botões de validação\n",
    "            if b is start_validation_button:\n",
    "                 human_validation_results['total_images'] += 1\n",
    "                 buttons_box.layout.visibility = 'visible'\n",
    "                 start_validation_button.layout.visibility = 'hidden' # Esconde o botão de iniciar\n",
    "            else: # para cliques subsequentes (sucesso/falha)\n",
    "                 human_validation_results['total_images'] += 1\n",
    "\n",
    "\n",
    "        except StopIteration:\n",
    "            # O iterador acabou, finalizamos a validação\n",
    "            buttons_box.layout.visibility = 'hidden' # Esconde os botões de sucesso/falha\n",
    "            display_final_human_validation_stats()\n",
    "            return\n",
    "\n",
    "def on_success_click(b):\n",
    "    human_validation_results['successful_detections'] += 1\n",
    "    on_button_clicked(b) # Chama diretamente para processar a próxima imagem\n",
    "\n",
    "def on_fail_click(b):\n",
    "    human_validation_results['failed_detections'] += 1\n",
    "    on_button_clicked(b) # Chama diretamente para processar a próxima imagem\n",
    "\n",
    "# Associa as funções aos eventos de clique\n",
    "start_validation_button.on_click(on_button_clicked)\n",
    "success_button.on_click(on_success_click)\n",
    "fail_button.on_click(on_fail_click)\n",
    "\n",
    "# Exibe os widgets na tela\n",
    "print(\"Clique em 'Iniciar Validação' para começar a avaliar as detecções.\")\n",
    "display(start_validation_button, output_area, buttons_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resultados e Conclusões\n",
    "Esta seção apresenta os resultados finais de desempenho do sistema de detecção de código de barras, com base exclusivamente na **validação humana**. Discutimos a eficácia do algoritmo e as possíveis melhorias com base nos dados coletados manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta célula deve ser executada após a conclusão da \"Validação Humana\"\n",
    "# Ela exibe um resumo dos resultados coletados para facilitar a visualização\n",
    "\n",
    "print(\"\\n=== RESULTADOS GERAIS DO ALGORITMO (Baseado na Validação Humana) ===\")\n",
    "\n",
    "if human_validation_results['total_images'] > 0:\n",
    "    taxa_sucesso = (human_validation_results['successful_detections'] / human_validation_results['total_images'] * 100)\n",
    "    \n",
    "    print(f\"Total de imagens validadas: {human_validation_results['total_images']}\")\n",
    "    print(f\"Detecções bem-sucedidas: {human_validation_results['successful_detections']}\")\n",
    "    print(f\"Detecções mal-sucedidas: {human_validation_results['failed_detections']}\")\n",
    "    print(f\"Taxa de Sucesso (Humana): {taxa_sucesso:.2f}%\")\n",
    "\n",
    "    # Plot dos Resultados da Validação Humana\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    human_metrics = ['Bem-sucedidas (Humana)', 'Mal-sucedidas (Humana)']\n",
    "    human_values = [human_validation_results['successful_detections'], human_validation_results['failed_detections']]\n",
    "    bars = plt.bar(human_metrics, human_values, color=['lightgreen', 'salmon'])\n",
    "    plt.title('Resultados da Validação Humana')\n",
    "    plt.ylabel('Número de Imagens')\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval, int(yval), va='bottom', ha='center') # va='bottom' para colocar o texto acima da barra\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Nenhuma validação humana foi realizada ainda. Execute a seção de validação para gerar os resultados.\")\n",
    "\n",
    "print(\"\\n--- Conclusões ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instruções para Execução\n",
    "\n",
    "1. Crie uma pasta chamada `imagens` no mesmo diretório do notebook.\n",
    "2. Coloque suas imagens de teste na pasta `imagens`.\n",
    "3. **Certifique-se de que pelo menos 3 imagens existam na pasta `imagens` para que os exemplos funcionem adequadamente.**\n",
    "4. Execute todas as células do notebook sequencialmente.\n",
    "5. Na seção \"Exemplos de Processamento por Etapas\", use os controles interativos para ajustar parâmetros e visualizar as etapas de processamento.\n",
    "6. Na seção \"Validação Humana das Detecções\", clique em \"Iniciar Validação\" e use os botões \"Sucesso\" ou \"Falha\" para classificar cada detecção exibida.\n",
    "7. Os resultados da validação humana serão exibidos na seção \"Resultados e Conclusões\" após a finalização da etapa anterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
